{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b451ed9-d7df-43aa-9792-d8789f05b448",
   "metadata": {},
   "source": [
    "<!---ï»¿---\n",
    "layout: post\n",
    "title: \"Invertible calculus\"\n",
    "tags: [Math, Calculus, Fractional-Calculus]\n",
    "math: true\n",
    "---\n",
    "-->\n",
    "\n",
    "# Intro #\n",
    "intro, Fractional calculus, did't know how to fix problems in FC, so try simplified slightly tangential problem in calculus. invertibility of the derivative, if we look at the fundamental theorem of calculus along with the Leibniz integral theorem\n",
    "\n",
    "- symbolic D S f /= S D f\n",
    "$\\frac{d}{dx}\\int_0^x f(t)dt = f(x) \\neq \\int_0^x \\frac{d}{dt} f(t) dt = f(x) - f(0)$\n",
    "\n",
    "from that you can see that the constants of integration in the process of antidifferentiation and likewise the bounds of integration are closely related to why derivatives are not invertible. however there is clearer way to look at it if we consider only complex analytic functions. they have the property that the Taylor series of complex analytic function can all ways be analytically continued to the full domain of the analytic function. so the local behaviour of the Taylor series defines the behaviour of the full function. so we can completely characterize an analytic function by the coefficients of the Taylor series.\n",
    "\n",
    "- symbolic derivative a_n -> a_{n - 1}\n",
    "$\\frac{d}{dx} f(x) := (a_0, a_1, a_2, ...) \\rightarrow (a_1, a_2, a_3, ...)$\n",
    "$\\int_0^x f(t)dt + a := (a_1, a_2, a_3, ...) \\rightarrow (a, a_1, a_2, ...)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739cd206-63bb-4e5d-8779-d6c06e4c30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Code f as symbolic and Taylor def D def S. show and plot D S f and S D f for a particular f\n",
    "\n",
    "type TaylorSeries = [Double]\n",
    "\n",
    "derivative :: TaylorSeries -> TaylorSeries\n",
    "derivative (a_0:a_k) = a_k\n",
    "\n",
    "antiderivative :: Double -> TaylorSeries -> TaylorSeries\n",
    "antiderivative a a_k = a:a_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7de20d-362e-441e-a81d-e230c78a726d",
   "metadata": {},
   "source": [
    "So the derivative is not invertible because the information contained in the first term of the Taylor series is lost during differentiation and it is impossible to completely invert this process.\n",
    "\n",
    "# Stack Functions #\n",
    "so what if the derivative did not loose information, looking at the behaviour of derivative and integrals on the terms of the Taylor series. differentiation removes the first element in the sequence of Taylor coefficients, and antidifferention adds the constant of integration to the beginning of the sequence of coefficients. the loss of information makes the derivative not invertible but what if the information was not lost but maintained with the function. adding the necessary information to invert the derivative each time one is taken and removing it when it is used to compute the corresponding antiderivative. it would be possible to in general invert the process of differentiation. so what should the structure of such an object be. it should be the function plus some a sequence of extra information. since we are discussing analytic functions which are infinitely differentiable and can be integrated infinitely so the extra information must be an infinitely long sequence to contain all of the information of derivatives that have been taken and antiderivative that can be taken. also we need to consider the order that the information is interacted with, if you have a function and take a number of derivative and after words take an antiderivative, then the antiderivate should use the information added by the last derivative, so the information is accessed in a \"last in first out\" order, so the extra information is accessed by differentiation, and integration like a stack from computer science. so lets define a new function we will call a stack function that consists of a pair of complex analytic function and a infinite sequence of numbers indexed from one to infinity. lets now define a derivative which acts on these stack functions, such that information is preserved\n",
    "\n",
    "- symbolic D, S\n",
    "\n",
    "so under these definitions of differentiation and antidifferentiation, these operations move information from the Taylor series of the function to the stack and vise versa for antidifferentiaion. and this simple movement of information is simply and uniquely invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bc819-6dea-4b31-8955-79fb31d4119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- code D S f == S D f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d86c48-459a-46ab-9b7a-10d60eac7fc1",
   "metadata": {},
   "source": [
    "so this  this new derivative and antiderivative operator are invertible so if we consider repeated composition of the derivative on stack functions it defines an abelian group.\n",
    "\n",
    "\n",
    "#Analytic Functions\n",
    "if we only consider stack functions constructed from analytic functions, then we can produce a new representation of stack functions where the function in a stack function is represented by the sequence of coefficients of its Taylor series. so in this representation the stack function would be two sequences, the coefficients of the Taylor series and then the coefficients of the stack. now taking the derivation of a function using this representation what it does is removes the first element from the sequence of Taylor coefficients and adds it to the beginning of the stack.\n",
    "\n",
    "- symbolic ([a, a, a, ...], [b, b, b, ...]) -> ([a, a, ...], [a, b, b, b, ...])\n",
    "\n",
    "so we can see taking derivatives and antiderivative just move the first element from the Taylor coefficients to the stack and vise versa. so alternatively we could represent this function as a single sequence indexed from minus infinity to infinity, with the elements indexed from zero to infinity containing the Taylor coefficients, the elements with negative index contain the elements of the stack with the absolute value of the index (reverse order from zero). taking the derivative of an object in this representation simply shifts all of the elements of the sequence to the left, and antidifferentiation moves them to the right. so calculus operators in this representation is equivalent to shifting the elements of this list (which does not remove any information and is invertible)\n",
    "\n",
    "- symbolic define Delta, then use that to define D, S\n",
    "\n",
    "\n",
    "# Is it a derivative? #\n",
    "so now on stack functions we have an operator that we call the derivative but how does it compare to the ordinary definitinition of derivative in terms of limits. before we can do that we need to define addition and scalar multiplication. looking at how addition and scalar multiplication act on analytic functions in terms of their Taylor series we can see an obvious consistent way to add and scale stack functions.\n",
    "\n",
    "- symbolic define addition and scaler multiplication\n",
    "\n",
    "before we can compare this definition of the derivative to the ordinary version. we need to be able to shift stack functions that is reproduce all of the values of a stack function with some offset. the stack function is just all of the derivatives and antiderivatives evaluated at some point, so if we compute the derivative and antiderivatives of a stack function at some other point then this can be combined to produce a new stack function that is a shifted version of the original. since we are only considering analytic function and the Taylor series of every analytic function has a nonzero radius of convergence then for any analytic stack function shifted versions of the stack function are all ways defined in terms of Taylor series for sufficiently small nonzero shifts.\n",
    "\n",
    "- symbolic shift operation\n",
    "\n",
    "so now we are ready to apply the ordinary definition of the derivative, i.e. the limit of the difference of shifted versions of a stack function over the amount shifted by, this should be in some sense the derivative of a stack function.\n",
    "\n",
    "- symbolic apply definition of derivative\n",
    "\n",
    "the limit definition of the derivative of a stack function reproduces the definition of a derivative in terms of shifting coefficients that was defined earlier. and so it is valid to use consider the shifting of terms of the stack function a derivative.\n",
    "\n",
    "\n",
    "# Reproduce calculus #\n",
    "we now have some justification in describing the operators previously described as derivative and anti derivative. since it is equal to result you would get when applying the normal limit definition of the derivative to a stack function and the antiderivative is the inverse operation. but how does this relate to the derivatives and integrals of ordinary function. lets define some functions, the projection operator psi that takes the extra information in a stack function and sets it to zero and a second function pi which constructs a normal function from a stack function by constructing the Taylor series from the coefficients in the stack function. using these two operations we can then explicitly define the ordinary derivative and integral of an analytic function in terms of these two operators.\n",
    "\n",
    "- symbolic psi=:sequence->Taylor polynomial pi=:projection\n",
    "\n",
    "rather than removing the extra information, if we set it to our desired constants of integration we can reproduce any definite integral of that form.\n",
    "\n",
    "# ODEs #\n",
    "is the extra information stored in stack functions in the coefficients with negative indices always arbitrary, or is there another way to get to stack functions, a natural way to construct stack functions. if we consider Homogeneous Linear Ordinary Differential Equations with Constant Coefficients. initial value problems of such operators can be solved by finding the recursive relation defining the operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252fabe-54ab-43ae-9ec2-70bdeccb90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- code example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0e2fb-e4c4-4cca-9160-6196baf80790",
   "metadata": {},
   "source": [
    "now if we are given a modified IVP where the initial valued supplied are for higher order derivatives, for example for a second order problem if the third and fourth derivative are given, then problems of this sort can also be solved using the recursive relation defined by the operation but we would also need to reverse the recursive relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf7a0e-a02f-4672-9b68-1801bc775cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- code example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a384b4f-fa61-4829-99dd-e82f063cab7a",
   "metadata": {},
   "source": [
    "using the reverse recursive equation we can find the lower order of the Taylor series (terms a2, a1, a0) this gives the full solution of f(x) that solves the IVP where Lf^(n)=0. then considering these types of solutions generally we are always looking for solutions where f(x) solves the IVP and L on any derivative of f(x) is zero, that is to say the function satisfies the initial conditions and the function and all of its derivative satisfy the recursive relation. so what if we use the reverses recursive relation to compute a hypothetical term a{-1}. - symbolic def y = int_0^x f + a-1 this is the only antiderivative of the solution f(x) which also solves Ly=0. this way we found that if we computed the term a{-1} it defines a unique antiderivative of the solution such that y and all of its derivatives satisfies the recursive relation and the derivative of the function satisfies the IVP. so if we take coefficients with negative indices seriously it can then be thought of as finding the unique nth order antiderivative such that the IVP is satisfied and it and all of its derivative satisfies the recursive relation. this would then expand the sequence of Taylor series to generalized sequence indexed from negative infinity to infinity. this sequence would be uniquely defined and such that it satisfies the recursive relationship for all terms and it satisfies the IVP. If we interpret the function as a stack function the it the unique stack function such that its derivatives and antiderivatives satisfy Ly=0.\n",
    "\n",
    "- symbolic sections\n",
    "\n",
    "so Homogeneous linear ordinary differential equations with constant coefficients naturally define stack functions as their solutions. so if you consider this more general Taylor series these solution are stack functions. stack functions naturally exist as solutions to problems of this type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848eb0d-3979-41c2-9fa9-0725197a0a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "8.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
